# Tutorial

```elixir
Mix.install([
  # {:openai_responses, "~> 0.3.0"},
  {:openai_responses, path: "~/src/openai_responses"},
  {:kino, "~> 0.11.0"}
])
```

## Introduction

The only setup you need for using the library is to get your OpenAI API token. If you already have the `OPENAI_API_KEY` environment variable set, then you can start right away.

```elixir
alias OpenAI.Responses
alias OpenAI.Responses.Helpers
```

<!-- livebook:{"branch_parent_index":0} -->

## Basic usage

`create/2` requires just two arguments: the name of the model, and the input text:

```elixir
{:ok, response} = Responses.create("gpt-4o", "Write a haiku about programming")
```

The `response` is just a map, and you can use helper functions to extract information from it:

```elixir
Helpers.has_refusal?(response)
```

```elixir
Helpers.output_text(response)
```

```elixir
Helpers.token_usage(response)
```

You can also supplied additional parameters to the API call:

```elixir
{:ok, response} =
  Responses.create(
    "gpt-4o",
    "Do you need semicolons in Elixir",
    instructions: "Talk like a pirate"
  )
IO.puts Helpers.output_text(response)
```

A *structured* input can be manually constructed and passed to `create/2`:

```elixir
{:ok, response} =
  Responses.create(
    "gpt-4o",
    [
      %{role: "user", content: "knock knock."},
      %{role: "assistant", content: "Who's there?"},
      %{role: "user", content: "Orange."}
    ]
  )
IO.puts Helpers.output_text(response)
```

```elixir
input = [
  %{
    "role" => "user",
    "content" => [
      %{"type" => "input_text", "text" => "What is in this image?"},
      %{
        "type" => "input_image",
        "image_url" => "https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg"
      }
    ]
  }
]

{:ok, response} = OpenAI.Responses.create("gpt-4o", input)
IO.puts Helpers.output_text(response)
```

<!-- livebook:{"branch_parent_index":0} -->

## Image helpers

As we saw in the previous section, you can manually create a structured input with images, but this requires writing verbose JSON-like structures. The library provides helper functions to make this process more ergonomic.

```elixir
# Using the helper function to create a message with an image
input_message = Helpers.create_message_with_images(
  "What is in this image?", 
  "https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg"
)

# The helper creates the same structure as the manual approach, but with less code
input_message
```

You can also specify multiple images with different detail levels:

```elixir
multi_image_message = Helpers.create_message_with_images(
  "Compare these two images",
  [
    {"https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg", "high"},
    "https://upload.wikimedia.org/wikipedia/commons/4/48/Cocacolacollection.JPG"
  ],
  detail: "low"  # Default detail level for images without a specific level
)

# And then use it with the API
{:ok, response} = OpenAI.Responses.create("gpt-4o", [multi_image_message])
IO.puts Helpers.output_text(response)
```

Local image files are also supported and will be automatically encoded as base64 data URLs:

```elixir
# This would work if you have these image files locally
# local_image_message = Helpers.create_message_with_images(
#   "Describe these local images",
#   ["path/to/image1.jpg", "path/to/image2.png"]
# )
```

The helper function eliminates boilerplate code, handles encoding of local images, and provides a more intuitive interface for working with images in your prompts.

<!-- livebook:{"branch_parent_index":0} -->

## Using built-in tools

The usage of built-in tools can be illustrated by the following example:

```elixir
{:ok, response_no_tools} = Responses.create("gpt-4o", "What's the weather in San Francisco?")
IO.puts(Helpers.output_text(response_no_tools))
```

```elixir
{:ok, response_with_search} =
  Responses.create("gpt-4o", "What's the weather in San Francisco?",
    tools: [%{type: "web_search_preview"}],
    temperature: 0.7
  )

IO.puts(Helpers.output_text(response_with_search))
```

<!-- livebook:{"branch_parent_index":0} -->

## Structured outputs

Structured output ensures the model always generates responses that adhere to your supplied JSON Schema.

```elixir
alias OpenAI.Responses.Schema

# Define a schema for a calendar event
calendar_event_schema = Schema.object(%{
  name: :string,
  date: :string,
  participants: {:array, :string}
})

# Parse a response with structured output
{:ok, event} = Responses.parse(
  "gpt-4o", 
  "Alice and Bob are going to a science fair on Friday.", 
  calendar_event_schema,
  schema_name: "event"
)

# Access the parsed data
event.parsed
```

```elixir
# Define a more complex schema with nested objects
math_reasoning_schema = Schema.object(%{
  steps: {:array, Schema.object(%{
    explanation: :string,
    output: :string
  })},
  final_answer: :string
})

# Parse with the complex schema
{:ok, solution} = Responses.parse(
  "gpt-4o", 
  "Solve 8x + 7 = -23", 
  math_reasoning_schema
)

solution.parsed
```

The returned map also defines `:raw_response` and `:token_usage` if you need to get additional metadata from the LLM provider.

```elixir
solution.raw_response
```

<!-- livebook:{"branch_parent_index":0} -->

## Streaming responses

OpenAI.Responses supports true streaming, where you can process chunks as they arrive without waiting for the entire response to complete.

<!-- livebook:{"break_markdown":true} -->

### Real-time text streaming

This example demonstrates how to display text as it arrives in real-time using Kino.Frame:

```elixir
frame = Kino.Frame.new()
Kino.render(frame)

# Create a stream from OpenAI
stream = Responses.stream("gpt-4o", "Write a short poem about coding in Elixir")

# Extract text deltas - no need for initializing a stream handler
text_stream = Responses.text_deltas(stream)

Kino.Frame.append(frame, Kino.Markdown.new("## Poem about coding\n"))

# Process the stream
text_stream
|> Stream.each(fn delta ->
  Kino.Frame.append(frame, Kino.Markdown.new(delta, chunk: true))
end)
|> Stream.run()


Kino.Frame.append(frame, Kino.Markdown.new("\n\n*Generation complete* ✨"))

:done
```

You can also combine structured outputs with real-time streaming:

### Structured Streaming with Kino.Frame

This example demonstrates combining structured output (using a JSON schema) with streaming to incrementally display data as it's generated. We'll request information about the first 20 US presidents and display each president's details in a `Kino.Frame` as soon as they are received.

```elixir
alias OpenAI.Responses.Schema

# Define the schema for a single president's information
president_schema = Schema.object(%{
  name: :string,
  presidency_start_year: :integer,
  presidency_end_year: :integer,
  biography_summary: :string,
  unusual_fact: :string
})

# Define the schema for a list of presidents
presidents_list_schema = Schema.array(president_schema)

# Setup Kino.Frame for displaying results
presidents_frame = Kino.Frame.new() |> Kino.render()

Kino.Frame.append(presidents_frame, Kino.Markdown.new("## First 20 US Presidents (Structured Streaming)\n"))
Kino.Frame.append(presidents_frame, Kino.Text.new("Requesting data from OpenAI...\n\n"))

# Create the stream request with the structured output schema
stream = Responses.parse_stream(
  "gpt-4o", 
  "Provide information about the first 20 US presidents. For each, include their name, presidency start and end years, a brief biography summary (1-2 sentences), and one unusual fact.",
  presidents_list_schema,
  schema_name: "presidents_list" # Naming the schema
)

# Process the stream provided by parse_stream. 
# It should yield parsed structured data directly.
stream
|> Stream.each(fn event ->
  case event do
    # Assuming parse_stream yields {:delta, parsed_object} for each item
    {:delta, president_data} when is_map(president_data) ->
      # Check if the received data matches the expected structure (using atom keys)
      if Map.has_key?(president_data, :name) do
        md_content = """
        ### #{president_data.name} (#{president_data.presidency_start_year}-#{president_data.presidency_end_year})
        **Bio:** #{president_data.biography_summary}
        **Unusual Fact:** #{president_data.unusual_fact}
        ---
        """
        Kino.Frame.append(presidents_frame, Kino.Markdown.new(md_content))
      else
        # Log if we receive a map that doesn't look like a president object
        Kino.Frame.append(presidents_frame, Kino.Text.new("Received unexpected structured data: #{inspect(president_data)}"))
      end
      
    # Handle potential final event or other event types if necessary
    {:done, final_data} ->
      # Optionally handle the final complete data if needed
      Kino.Frame.append(presidents_frame, Kino.Text.new(inspect(final_data)))
      
    event ->
      # Log or ignore other event types from parse_stream
      Kino.Frame.append(presidents_frame, Kino.Text.new("Received other event: #{inspect(event)}"))
  end
end)
|> Stream.run()

Kino.Frame.append(presidents_frame, Kino.Markdown.new("\n\n*Streaming complete* ✅"))

:ok
```
